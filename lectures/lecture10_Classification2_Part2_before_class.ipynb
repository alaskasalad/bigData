{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7f9edb",
   "metadata": {},
   "source": [
    "# Lecture 10: Classification2 Part 2\n",
    "1. Logistic function\n",
    "2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbe8b3a",
   "metadata": {},
   "source": [
    "### 1. Logistic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def logistic(z):\n",
    "    return np.exp(z)/(1+np.exp(z))\n",
    "\n",
    "t = np.arange(-10, 11)\n",
    "\n",
    "plt.plot(t, logistic(t), 'r--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5617c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(p):\n",
    "    return np.log(p/(1-p))\n",
    "\n",
    "t = np.arange(-10, 11)\n",
    "\n",
    "plt.plot(t, logit(logistic(t)), 'bs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a3423",
   "metadata": {},
   "source": [
    "### 2. Logistic Regression Example 1:\n",
    "Pima Indians Diabetes Database. You can download the data at https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "import pandas as pd\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "# load dataset\n",
    "pima = pd.read_csv(\"pima-indians-diabetes.csv\", header=None, names=col_names)\n",
    "\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef7e2e",
   "metadata": {},
   "source": [
    "Split dataset in features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
    "X = pima[feature_cols] # Features\n",
    "y = pima.label # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f05684",
   "metadata": {},
   "source": [
    "Split X and y into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d580b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c3d6d",
   "metadata": {},
   "source": [
    "Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c58f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16,max_iter=1000)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8796ca7",
   "metadata": {},
   "source": [
    "Model Evaluation using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f1da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac609a6",
   "metadata": {},
   "source": [
    "Visualizing Confusion Matrix using Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b145ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_names=[0,1] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3dc0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['without diabetes', 'with diabetes']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde05e0",
   "metadata": {},
   "source": [
    "ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc4d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[:,1]   #Probability estimates\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\n",
    "plt.plot(fpr,tpr)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1994c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e0970",
   "metadata": {},
   "source": [
    "### Logistic Regression Example 2: \n",
    "Breast Cancer Wisconsin (Original) Data Set. You can download the data at https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = pd.read_csv('breast-cancer-wisconsin.csv')\n",
    "bc = bc.dropna()  #drops instances with missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc12e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc['class'] = bc['class'].astype('category')\n",
    "bc['class'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bba354",
   "metadata": {},
   "source": [
    "We separate the labels from the rest of the dataset by dropping the appropriate column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1abb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bc.drop(['class'], axis=1)\n",
    "X = X.values\n",
    "Y_raw = bc['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4a428",
   "metadata": {},
   "source": [
    "It would make our task easier to use '0' and '1' as the labels for our classes instead of the labels used by in the original dataset. This can easily be done with LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(Y_raw)\n",
    "Y = label_enc.transform(Y_raw)\n",
    "\n",
    "#print(Y_raw)\n",
    "#print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef90b8c",
   "metadata": {},
   "source": [
    "we can invert the label encoding with _label_enc.inverse_transform()_ later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain, XTest, YTrain, YTest = train_test_split(X, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa6696",
   "metadata": {},
   "source": [
    "We are going to use regularisation in our model and we can choose between L1 and L2 penalties. The hyperparameter in this case is implemented as C and it corresponds to the inverse of the regularisation strength. This means that the smaller the value of C, the stronger the penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "pen_val = ['l1','l2']\n",
    "C_val = 2. ** np.arange(-5, 10, step=2)\n",
    "grid_s = [{'C': C_val, 'penalty': pen_val}]\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "#model = LogisticRegression(max_iter=1000,solver='liblinear')\n",
    "\n",
    "cv_logr = GridSearchCV(estimator=model, param_grid=grid_s, cv=ms.KFold(n_splits=10))\n",
    "\n",
    "cv_logr.fit(XTrain, YTrain)\n",
    "best_c = cv_logr.best_params_['C']\n",
    "best_penalty = cv_logr.best_params_['penalty']\n",
    "\n",
    "print(\"The best parameters are: cost={0} and penalty={1}\".format(best_c, best_penalty))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7727347",
   "metadata": {},
   "source": [
    "Read https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Run again with the best setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_clf = LogisticRegression(C=best_c,penalty=best_penalty,solver='liblinear')\n",
    "b_clf.fit(XTrain, YTrain)\n",
    "\n",
    "predict = b_clf.predict(XTest)\n",
    "y_proba = b_clf.predict_proba(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f3d3f",
   "metadata": {},
   "source": [
    "The accuracy of the model can be seen with the score method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_clf.score(XTest, YTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141158ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold=metrics.roc_curve(YTest, y_proba[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
