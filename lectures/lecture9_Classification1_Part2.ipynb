{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7f9edb",
   "metadata": {},
   "source": [
    "# Lecture 9: Classification1 Part 2\n",
    "3 Examples of K-Nearest Neighbors Classification (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a3423",
   "metadata": {},
   "source": [
    "### Example 1:\n",
    "Warm up.\n",
    "\n",
    "Suppose that we have a training set __X__, with a set of known labels __Y__. Then we use those to initialize the model. (In this case, we set k = 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import neighbors \n",
    "X= np.array([[1,1,3,4],\n",
    "             [2,1,5,5],\n",
    "             [5,5,1,2],\n",
    "             [5,4,1,3],\n",
    "             [5,5,1,1]])\n",
    "Y = np.array([1,2,3,4,5])\n",
    "nbrs = neighbors.KNeighborsClassifier(1)\n",
    "nbrs.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef7e2e",
   "metadata": {},
   "source": [
    "Now, suppose we would like to classify the following testing set __T__, we do that as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ad1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "T= np.array([[1,2,3,1],\n",
    "             [5,3,2,1]])\n",
    "nbrs.predict(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e0970",
   "metadata": {},
   "source": [
    "### Example 2: \n",
    "Let's do real example with [Iris Dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d5705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "n_neighbors = 15\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure()\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "            edgecolor='k', s=20)\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.title(\"3-Class classification (k = %i)\"\n",
    "          % (n_neighbors))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bba354",
   "metadata": {},
   "source": [
    "There are different weighting schemes available:\n",
    "\n",
    "* Uniform: all points in the set of k closest neighbors are weighted equally. (Default in sklearn)\n",
    "* Distance: Points are weighted by 1/distance.\n",
    "\n",
    "Try\n",
    "```\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors, weights=\"distance\")\n",
    "```\n",
    "in above example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c576a49c",
   "metadata": {},
   "source": [
    "### Example 3: \n",
    "A-Z\n",
    "\n",
    "First split the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "\n",
    "XTrain, XTest, YTrain, YTest = ms.train_test_split(X, Y, test_size= 0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k_neighbours = list(range(1,21,2))   \n",
    "n_grid = [{'n_neighbors': k_neighbours}]\n",
    "\n",
    "model = neighbors.KNeighborsClassifier()\n",
    "cv_knn = GridSearchCV(estimator=model, param_grid=n_grid, cv=ms.KFold(n_splits=10))\n",
    "cv_knn.fit(XTrain, YTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd4d115",
   "metadata": {},
   "source": [
    "This is the best $K$ for the **training** set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = cv_knn.best_params_['n_neighbors']\n",
    "print(best_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e090e",
   "metadata": {},
   "source": [
    "Use best $K$ to predict test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b897688",
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclf = neighbors.KNeighborsClassifier(n_neighbors=best_k)\n",
    "knnclf.fit(XTrain, YTrain)\n",
    "\n",
    "y_pred = knnclf.predict(XTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c1b95",
   "metadata": {},
   "source": [
    "Print Confusion Matrix or Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(YTest,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528969de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(YTest, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc803460",
   "metadata": {},
   "source": [
    "$F_1$ score provides a measure of classification quality based on the precision and recall:\n",
    "$$ F_1=2 \\frac{precision\\times recall}{precision+recall}$$\n",
    "where 1 is the best possible value and 0 is the worst possible value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
